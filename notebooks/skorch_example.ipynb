{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11c2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection._split import _RepeatedSplits\n",
    "from skorch.callbacks import Callback\n",
    "from skorch.dataset import CVSplit, get_len\n",
    "from skorch.utils import to_numpy\n",
    "from torch import nn\n",
    "from lifelines.utils import concordance_index\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d57998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Tong, Li, et al. \"Deep learning based feature-level integration of multi-omics data for breast cancer patients survival analysis.\" BMC medical informatics and decision making 20.1 (2020): 1-12.\n",
    "# https://github.com/tongli1210/BreastCancerSurvivalIntegration/blob/master/src/models/loss_survival.py\n",
    "def get_R_matrix_moded_dave(survival_time):\n",
    "    \"\"\"\n",
    "    Create an indicator matrix of risk sets, where T_j >= T_i.\n",
    "\n",
    "    Input:\n",
    "        survival_time: a Pytorch tensor that the number of rows is equal top the number of samples\n",
    "    Output:\n",
    "        indicator matrix: an indicator matrix\n",
    "    \"\"\"\n",
    "    surv_time = np.array(survival_time)\n",
    "    return (np.outer(surv_time, surv_time) >= np.transpose([np.square(survival_time)] * survival_time.shape[0])).astype(int).T\n",
    "\n",
    "def get_R_matrix_moded(survival_time):\n",
    "    \"\"\"\n",
    "    Create an indicator matrix of risk sets, where T_j >= T_i.\n",
    "\n",
    "    Input:\n",
    "        survival_time: a Pytorch tensor that the number of rows is equal top the number of samples\n",
    "    Output:\n",
    "        indicator matrix: an indicator matrix\n",
    "    \"\"\"\n",
    "    surv_time = np.array(survival_time)\n",
    "    return (np.outer(surv_time, surv_time) >= np.square(surv_time)).astype(int).T\n",
    "\n",
    "# Adapted from Tong, Li, et al. \"Deep learning based feature-level integration of multi-omics data for breast cancer patients survival analysis.\" BMC medical informatics and decision making 20.1 (2020): 1-12.\n",
    "# https://github.com/tongli1210/BreastCancerSurvivalIntegration/blob/master/src/models/loss_survival.py\n",
    "def neg_par_log_likelihood(\n",
    "    pred,\n",
    "    survival_time,\n",
    "    survival_event,\n",
    "    sample_weight,\n",
    "    cuda=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate the average Cox negative partial log-likelihood\n",
    "    Input:\n",
    "        pred: linear predictors from trained model.\n",
    "        survival_time: survival time from ground truth\n",
    "        survival_event: survival event from ground truth: 1 for event\n",
    "                and 0 for censored\n",
    "    Output:\n",
    "        cost: the survival cost to be minimized\n",
    "    \"\"\"\n",
    "    sample_weight = torch.unsqueeze(sample_weight, 1)\n",
    "    survival_event = torch.tensor(survival_event)\n",
    "    survival_time = torch.tensor(survival_time)\n",
    "    n_observed = survival_event.sum(0)\n",
    "    if not n_observed:\n",
    "        # Return zero loss if there are no events\n",
    "        # within a batch.\n",
    "        return torch.tensor(0.0)\n",
    "    R_matrix = get_R_matrix_moded(survival_time)\n",
    "    R_matrix = torch.Tensor(R_matrix)\n",
    "    if cuda:\n",
    "        R_matrix = R_matrix.cuda()\n",
    "    risk_set_sum = R_matrix.mm(torch.exp(pred))\n",
    "    diff = pred - torch.log(risk_set_sum)\n",
    "    survival_event = torch.reshape(\n",
    "        survival_event, (survival_event.shape[0], 1)\n",
    "    )\n",
    "    sum_diff_in_observed = (\n",
    "        torch.transpose(diff * sample_weight, 0, 1).float().mm(survival_event)\n",
    "    )\n",
    "    loss = (-(sum_diff_in_observed) / n_observed).reshape((-1,))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0b4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ae_criterion(nn.Module):\n",
    "    def forward(self, prediction, target, sample_weight=None):\n",
    "        if not sample_weight:\n",
    "            sample_weight = torch.ones(prediction[0].shape[0])\n",
    "        mse = nn.MSELoss()\n",
    "        return neg_par_log_likelihood(\n",
    "                prediction[0],\n",
    "                np.array([str.rsplit(i, \"|\")[1] for i in target]).astype(\n",
    "                    np.float32\n",
    "                ),\n",
    "                np.array([str.rsplit(i, \"|\")[0] for i in target]).astype(\n",
    "                    np.float32\n",
    "                ),\n",
    "                sample_weight,\n",
    "        ) + mse(prediction[1], prediction[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07846a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Base class modeling the encoder portion of an autoencoder.\n",
    "\n",
    "    Attributes:\n",
    "        input_dimension: Input size going into the encoder.\n",
    "        hidden_layer_size: Number of hidden nodes within each hidden layer of the encoder.\n",
    "        activation: Non-linear activation method to be used by the encoder.\n",
    "        hidden_layers: Number of hidden layers within the encoder.\n",
    "        embedding_dimension: Dimensionality of the final output of the encoder (i.e., the latent space).\n",
    "        encode: `torch.Sequential` module containing the full encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dimension,\n",
    "        hidden_layer_size=128,\n",
    "        activation=nn.PReLU,\n",
    "        hidden_layers=1,\n",
    "        embedding_dimension=64,\n",
    "        p_dropout=0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        encoder = []\n",
    "        current_size = input_dimension\n",
    "        next_size = hidden_layer_size\n",
    "        for i in range(hidden_layers):\n",
    "            if i != 0:\n",
    "                current_size = next_size\n",
    "                # Slowly halve size of the AE hidden layer dimension\n",
    "                # over time until we reach the embedding dimension.\n",
    "                # Take max since we do not want the non-bottleneck\n",
    "                # layers to become smaller than the bottleneck.\n",
    "                next_size = max(int(next_size / 2), embedding_dimension)\n",
    "            encoder.append(nn.Linear(current_size, next_size))\n",
    "            encoder.append(activation())\n",
    "            encoder.append(nn.BatchNorm1d(next_size))\n",
    "            encoder.append(nn.Dropout(p_dropout))\n",
    "        if hidden_layers > 0:\n",
    "            encoder.append(nn.Linear(next_size, embedding_dimension))\n",
    "        else:\n",
    "            encoder.append(nn.Linear(input_dimension, embedding_dimension))\n",
    "        # Do not include an activation before the embedding.\n",
    "        self.encode = nn.Sequential(*encoder)\n",
    "        self.input_dimension = input_dimension\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.activation = activation\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encode(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Base class modeling the decoder portion of an autoencoder.\n",
    "\n",
    "    Attributes:\n",
    "        decode: `torch.Sequential` module containing the full decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, activation=nn.PReLU, p_dropout=0.0):\n",
    "        super().__init__()\n",
    "        decoder = []\n",
    "        # Build up the decoder symmetrically from the encoder.\n",
    "        for layer in encoder.encode[::-1][::4]:\n",
    "            current_size = layer.weight.shape[0]\n",
    "            next_size = layer.weight.shape[1]\n",
    "            decoder.append(nn.Linear(current_size, next_size))\n",
    "            decoder.append(activation())\n",
    "            decoder.append(nn.BatchNorm1d(next_size))\n",
    "            decoder.append(nn.Dropout(p_dropout))\n",
    "        self.decode = nn.Sequential(*(decoder[:-3]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(x)\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    \"\"\"Base class modeling an autoencoder.\n",
    "\n",
    "    Attributes:\n",
    "        encode: `torch.Sequential` module containing the full encoder.\n",
    "        decode: `torch.Sequential` module containing the full decoder.\n",
    "        input_dimension: Input size going into the encoder.\n",
    "        hidden_layer_size: Number of hidden nodes within each hidden layer of the encoder.\n",
    "        activation: Non-linear activation method to be used by the encoder.\n",
    "        hidden_layers: Number of hidden layers within the encoder.\n",
    "        embedding_dimension: Dimensionality of the final output of the encoder (i.e., the latent space).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dimension,\n",
    "        hidden_layer_size=128,\n",
    "        activation=nn.PReLU,\n",
    "        hidden_layers=1,\n",
    "        embedding_dimension=64,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encode = Encoder(\n",
    "            input_dimension,\n",
    "            hidden_layer_size,\n",
    "            activation,\n",
    "            hidden_layers,\n",
    "            embedding_dimension,\n",
    "        )\n",
    "        self.decode = Decoder(self.encode, activation)\n",
    "        self.input_dimension = input_dimension\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.activation = activation\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "\n",
    "class HazardRegression(nn.Module):\n",
    "    \"\"\"Base class modeling a cox hazard regression problem.\n",
    "\n",
    "    Attributes:\n",
    "        input_dimension: Number of covariates to be input to the cox regression.\n",
    "        hidden_layer_size: Number of hidden nodes within each hidden layer of the regression.\n",
    "        activation: Non-linear activation to be used after each hidden layer of the regression.\n",
    "        hidden_layers: Number of hidden layers to be used within the regression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dimension,\n",
    "        hidden_layer_size=32,\n",
    "        activation=nn.PReLU,\n",
    "        hidden_layers=0,\n",
    "        p_dropout=0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hazard = []\n",
    "        current_size = input_dimension\n",
    "        for layer in range(hidden_layers):\n",
    "            next_size = hidden_layer_size\n",
    "            hazard.append(nn.Linear(current_size, next_size))\n",
    "            hazard.append(activation())\n",
    "            hazard.append(nn.BatchNorm1d(current_size))\n",
    "            hazard.append(nn.Dropout(p_dropout))\n",
    "            current_size = next_size\n",
    "        hazard.append(nn.Linear(current_size, 1, bias=False))\n",
    "        self.hazard = nn.Sequential(*hazard)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.hazard(x)\n",
    "\n",
    "\n",
    "class SupervisedCoxAE(nn.Module):\n",
    "    def __init__(self, input_dimension):\n",
    "        super().__init__()\n",
    "        self.ae = AE(input_dimension)\n",
    "        self.hazard = HazardRegression(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded, decoded = self.ae(x)\n",
    "        hazard = self.hazard(encoded)\n",
    "        return hazard, x, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274b7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.datasets import load_flchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3d920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_flchain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2664089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0].dropna()[[\"age\", \"creatinine\", \"kappa\"]]\n",
    "target = data[1][X.index]\n",
    "target = np.array([f\"{int(i[0])}|{i[1]}\" for i in target])\n",
    "from skorch.net import NeuralNet\n",
    "\n",
    "class BaseSurvivalNeuralNet(NeuralNet):\n",
    "    def score(self, X: np.ndarray, y: np.ndarray):\n",
    "        try:\n",
    "            concordance = concordance_index(\n",
    "                event_times=np.vstack(np.char.split(np.array(y), sep=\"|\"))[\n",
    "                    :, 1\n",
    "                ].astype(np.float32),\n",
    "                predicted_scores=np.negative(np.squeeze(self.predict(X))),\n",
    "                event_observed=np.vstack(np.char.split(np.array(y), sep=\"|\"))[\n",
    "                    :, 0\n",
    "                ].astype(int),\n",
    "            )\n",
    "        except ValueError:\n",
    "            concordance = np.nan\n",
    "        return concordance\n",
    "    \n",
    "    def get_loss(self, y_pred, y_true, X=None, training=False):\n",
    "        return self.criterion_(y_pred, y_true)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "18b2b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m1688.5489\u001b[0m     \u001b[32m2429.6079\u001b[0m  0.1824\n",
      "      2     \u001b[36m1640.7899\u001b[0m     \u001b[32m2154.3174\u001b[0m  0.0530\n",
      "      3     \u001b[36m1562.3875\u001b[0m     \u001b[32m2028.8997\u001b[0m  0.0561\n",
      "      4     \u001b[36m1394.7387\u001b[0m     2379.1687  0.0609\n",
      "      5     \u001b[36m1048.3701\u001b[0m     3100.4685  0.0679\n",
      "      6      \u001b[36m555.0559\u001b[0m     2764.8933  0.0674\n",
      "      7      \u001b[36m196.5069\u001b[0m      \u001b[32m804.6316\u001b[0m  0.0641\n",
      "      8       \u001b[36m70.1939\u001b[0m      \u001b[32m391.5276\u001b[0m  0.0540\n",
      "      9       \u001b[36m41.8473\u001b[0m      456.0356  0.0510\n",
      "     10       \u001b[36m35.7961\u001b[0m      \u001b[32m387.7709\u001b[0m  0.0485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5892330985472448"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = BaseSurvivalNeuralNet(\n",
    "    module=SupervisedCoxAE,\n",
    "    module__input_dimension=X.shape[1],\n",
    "    criterion=ae_criterion,\n",
    "    lr=0.001\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(), net)\n",
    "net.fit(X.to_numpy().astype(np.float32), target)\n",
    "net.score(\n",
    "    X.to_numpy().astype(np.float32), target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7abe6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1|85.0', '1|1281.0', '1|69.0', ..., '1|51.0', '1|611.0',\n",
       "       '1|2188.0'], dtype='<U8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fdc37da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lifelines.utils import concordance_index\n",
    "from skorch.net import NeuralNet\n",
    "from sksurv.linear_model.coxph import BreslowEstimator\n",
    "from torch import nn\n",
    "from itertools import chain\n",
    "from operator import add\n",
    "import itertools\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "\n",
    "def transform_survival_target(time, event):\n",
    "    return np.array([f\"{time[i]}|{event[i]}\" for i in range(len(time))])\n",
    "\n",
    "def inverse_transform_survival_target(y):\n",
    "    return (\n",
    "        np.array([float(i.rsplit(\"|\")[0])for i in y]),\n",
    "        np.array([int(i.rsplit(\"|\")[1])for i in y])\n",
    "    )\n",
    "\n",
    "def inverse_transform_survival_function(y):\n",
    "    return np.vstack(\n",
    "        [np.array(i.rsplit(\"|\")) for i in y]\n",
    "    )\n",
    "\n",
    "class BaseSurvivalNeuralNet(NeuralNet):\n",
    "    def get_loss(self, y_pred, y_true, X=None, training=False):\n",
    "        return self.criterion_(y_pred, y_true)\n",
    "\n",
    "\n",
    "class HazardRegression(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dimension,\n",
    "        n_output,\n",
    "        hidden_layer_sizes,\n",
    "        activation=nn.ReLU,\n",
    "        p_dropout=0.0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        hidden_layer_sizes = hidden_layer_sizes + [n_output]\n",
    "        print(hidden_layer_sizes)\n",
    "        self.activation = activation\n",
    "        self.p_dropout = p_dropout\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.n_output = n_output\n",
    "        huh = list(flatten([\n",
    "                nn.Linear(input_dimension, hidden_layer_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p_dropout),\n",
    "            ]\n",
    "            + [\n",
    "                [\n",
    "                    nn.Linear(\n",
    "                        hidden_layer_sizes[i], hidden_layer_sizes[i + 1]\n",
    "                    ),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p_dropout),\n",
    "                ]\n",
    "                for i in range(len(hidden_layer_sizes) -1)\n",
    "            ]))\n",
    "        self.hazard = nn.Sequential(*flatten(\n",
    "        [\n",
    "                nn.Linear(input_dimension, hidden_layer_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p_dropout),\n",
    "            ]\n",
    "            + [\n",
    "                [\n",
    "                    nn.Linear(\n",
    "                        hidden_layer_sizes[i], hidden_layer_sizes[i + 1]\n",
    "                    ),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p_dropout),\n",
    "                ]\n",
    "                for i in range(len(hidden_layer_sizes) -1)\n",
    "            ]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b8e3952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 100, 1]\n"
     ]
    }
   ],
   "source": [
    "hm = HazardRegression(100, 1, [200, 100], nn.ReLU, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c937f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.hazard[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a4734a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HazardRegression(\n",
       "  (hazard): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=100, out_features=1, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "adf2df81",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum(): argument 'input' (position 1) must be Tensor, not generator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/8h444zld3558vyhdytd9tr3h0000gn/T/ipykernel_44277/2223013611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhazard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sum(): argument 'input' (position 1) must be Tensor, not generator"
     ]
    }
   ],
   "source": [
    "torch.sum(hm.hazard[1:].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f9b67d75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/8h444zld3558vyhdytd9tr3h0000gn/T/ipykernel_44277/1960978784.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhazard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "hu = [i for i in hm.hazard[1:].weight()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84829bbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/8h444zld3558vyhdytd9tr3h0000gn/T/ipykernel_44277/2577950012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhazard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "a = torch.sum(torch.cat([torch.norm(i) for i in hm.hazard[1:].parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c295f854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 4])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.hazard[0].weight[:, [0, 1, 2, 3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dbd94b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__dlpack__',\n",
       " '__dlpack_device__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__idiv__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__torch_function__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_backward_hooks',\n",
       " '_base',\n",
       " '_cdata',\n",
       " '_coalesced_',\n",
       " '_conj',\n",
       " '_conj_physical',\n",
       " '_dimI',\n",
       " '_dimV',\n",
       " '_fix_weakref',\n",
       " '_grad',\n",
       " '_grad_fn',\n",
       " '_indices',\n",
       " '_is_view',\n",
       " '_make_subclass',\n",
       " '_neg_view',\n",
       " '_nnz',\n",
       " '_python_dispatch',\n",
       " '_reduce_ex_internal',\n",
       " '_update_names',\n",
       " '_values',\n",
       " '_version',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'absolute',\n",
       " 'absolute_',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'acosh',\n",
       " 'acosh_',\n",
       " 'add',\n",
       " 'add_',\n",
       " 'addbmm',\n",
       " 'addbmm_',\n",
       " 'addcdiv',\n",
       " 'addcdiv_',\n",
       " 'addcmul',\n",
       " 'addcmul_',\n",
       " 'addmm',\n",
       " 'addmm_',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'addr_',\n",
       " 'align_as',\n",
       " 'align_to',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'aminmax',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'apply_',\n",
       " 'arccos',\n",
       " 'arccos_',\n",
       " 'arccosh',\n",
       " 'arccosh_',\n",
       " 'arcsin',\n",
       " 'arcsin_',\n",
       " 'arcsinh',\n",
       " 'arcsinh_',\n",
       " 'arctan',\n",
       " 'arctan_',\n",
       " 'arctanh',\n",
       " 'arctanh_',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'as_subclass',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'asinh',\n",
       " 'asinh_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan2_',\n",
       " 'atan_',\n",
       " 'atanh',\n",
       " 'atanh_',\n",
       " 'backward',\n",
       " 'baddbmm',\n",
       " 'baddbmm_',\n",
       " 'bernoulli',\n",
       " 'bernoulli_',\n",
       " 'bfloat16',\n",
       " 'bincount',\n",
       " 'bitwise_and',\n",
       " 'bitwise_and_',\n",
       " 'bitwise_left_shift',\n",
       " 'bitwise_left_shift_',\n",
       " 'bitwise_not',\n",
       " 'bitwise_not_',\n",
       " 'bitwise_or',\n",
       " 'bitwise_or_',\n",
       " 'bitwise_right_shift',\n",
       " 'bitwise_right_shift_',\n",
       " 'bitwise_xor',\n",
       " 'bitwise_xor_',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'broadcast_to',\n",
       " 'byte',\n",
       " 'cauchy_',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'cfloat',\n",
       " 'char',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'clip',\n",
       " 'clip_',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'col_indices',\n",
       " 'conj',\n",
       " 'conj_physical',\n",
       " 'conj_physical_',\n",
       " 'contiguous',\n",
       " 'copy_',\n",
       " 'copysign',\n",
       " 'copysign_',\n",
       " 'corrcoef',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'count_nonzero',\n",
       " 'cov',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'crow_indices',\n",
       " 'cuda',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumprod_',\n",
       " 'cumsum',\n",
       " 'cumsum_',\n",
       " 'data',\n",
       " 'data_ptr',\n",
       " 'deg2rad',\n",
       " 'deg2rad_',\n",
       " 'dense_dim',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diff',\n",
       " 'digamma',\n",
       " 'digamma_',\n",
       " 'dim',\n",
       " 'dist',\n",
       " 'div',\n",
       " 'div_',\n",
       " 'divide',\n",
       " 'divide_',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dsplit',\n",
       " 'dtype',\n",
       " 'eig',\n",
       " 'element_size',\n",
       " 'eq',\n",
       " 'eq_',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'erfinv_',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'exp2_',\n",
       " 'exp_',\n",
       " 'expand',\n",
       " 'expand_as',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'exponential_',\n",
       " 'fill_',\n",
       " 'fill_diagonal_',\n",
       " 'fix',\n",
       " 'fix_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float',\n",
       " 'float_power',\n",
       " 'float_power_',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'floor_divide',\n",
       " 'floor_divide_',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'fmod_',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'frexp',\n",
       " 'gather',\n",
       " 'gcd',\n",
       " 'gcd_',\n",
       " 'ge',\n",
       " 'ge_',\n",
       " 'geometric_',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_device',\n",
       " 'grad',\n",
       " 'grad_fn',\n",
       " 'greater',\n",
       " 'greater_',\n",
       " 'greater_equal',\n",
       " 'greater_equal_',\n",
       " 'gt',\n",
       " 'gt_',\n",
       " 'half',\n",
       " 'hardshrink',\n",
       " 'has_names',\n",
       " 'heaviside',\n",
       " 'heaviside_',\n",
       " 'histc',\n",
       " 'histogram',\n",
       " 'hsplit',\n",
       " 'hypot',\n",
       " 'hypot_',\n",
       " 'i0',\n",
       " 'i0_',\n",
       " 'igamma',\n",
       " 'igamma_',\n",
       " 'igammac',\n",
       " 'igammac_',\n",
       " 'imag',\n",
       " 'index_add',\n",
       " 'index_add_',\n",
       " 'index_copy',\n",
       " 'index_copy_',\n",
       " 'index_fill',\n",
       " 'index_fill_',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'inner',\n",
       " 'int',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'is_coalesced',\n",
       " 'is_complex',\n",
       " 'is_conj',\n",
       " 'is_contiguous',\n",
       " 'is_cuda',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_inference',\n",
       " 'is_leaf',\n",
       " 'is_meta',\n",
       " 'is_mkldnn',\n",
       " 'is_mlc',\n",
       " 'is_neg',\n",
       " 'is_nonzero',\n",
       " 'is_ort',\n",
       " 'is_pinned',\n",
       " 'is_quantized',\n",
       " 'is_same_size',\n",
       " 'is_set_to',\n",
       " 'is_shared',\n",
       " 'is_signed',\n",
       " 'is_sparse',\n",
       " 'is_sparse_csr',\n",
       " 'is_vulkan',\n",
       " 'is_xpu',\n",
       " 'isclose',\n",
       " 'isfinite',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'istft',\n",
       " 'item',\n",
       " 'kron',\n",
       " 'kthvalue',\n",
       " 'layout',\n",
       " 'lcm',\n",
       " 'lcm_',\n",
       " 'ldexp',\n",
       " 'ldexp_',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'lerp',\n",
       " 'lerp_',\n",
       " 'less',\n",
       " 'less_',\n",
       " 'less_equal',\n",
       " 'less_equal_',\n",
       " 'lgamma',\n",
       " 'lgamma_',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_normal_',\n",
       " 'log_softmax',\n",
       " 'logaddexp',\n",
       " 'logaddexp2',\n",
       " 'logcumsumexp',\n",
       " 'logdet',\n",
       " 'logical_and',\n",
       " 'logical_and_',\n",
       " 'logical_not',\n",
       " 'logical_not_',\n",
       " 'logical_or',\n",
       " 'logical_or_',\n",
       " 'logical_xor',\n",
       " 'logical_xor_',\n",
       " 'logit',\n",
       " 'logit_',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lt_',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'map2_',\n",
       " 'map_',\n",
       " 'masked_fill',\n",
       " 'masked_fill_',\n",
       " 'masked_scatter',\n",
       " 'masked_scatter_',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_exp',\n",
       " 'matrix_power',\n",
       " 'max',\n",
       " 'maximum',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'minimum',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'moveaxis',\n",
       " 'movedim',\n",
       " 'msort',\n",
       " 'mul',\n",
       " 'mul_',\n",
       " 'multinomial',\n",
       " 'multiply',\n",
       " 'multiply_',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'mvlgamma_',\n",
       " 'name',\n",
       " 'names',\n",
       " 'nan_to_num',\n",
       " 'nan_to_num_',\n",
       " 'nanmean',\n",
       " 'nanmedian',\n",
       " 'nanquantile',\n",
       " 'nansum',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'ndim',\n",
       " 'ndimension',\n",
       " 'ne',\n",
       " 'ne_',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'negative',\n",
       " 'negative_',\n",
       " 'nelement',\n",
       " 'new',\n",
       " 'new_empty',\n",
       " 'new_empty_strided',\n",
       " 'new_full',\n",
       " 'new_ones',\n",
       " 'new_tensor',\n",
       " 'new_zeros',\n",
       " 'nextafter',\n",
       " 'nextafter_',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'normal_',\n",
       " 'not_equal',\n",
       " 'not_equal_',\n",
       " 'numel',\n",
       " 'numpy',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'outer',\n",
       " 'output_nr',\n",
       " 'permute',\n",
       " 'pin_memory',\n",
       " 'pinverse',\n",
       " 'polygamma',\n",
       " 'polygamma_',\n",
       " 'positive',\n",
       " 'pow',\n",
       " 'pow_',\n",
       " 'prelu',\n",
       " 'prod',\n",
       " 'put',\n",
       " 'put_',\n",
       " 'q_per_channel_axis',\n",
       " 'q_per_channel_scales',\n",
       " 'q_per_channel_zero_points',\n",
       " 'q_scale',\n",
       " 'q_zero_point',\n",
       " 'qr',\n",
       " 'qscheme',\n",
       " 'quantile',\n",
       " 'rad2deg',\n",
       " 'rad2deg_',\n",
       " 'random_',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'record_stream',\n",
       " 'refine_names',\n",
       " 'register_hook',\n",
       " 'reinforce',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'remainder_',\n",
       " 'rename',\n",
       " 'rename_',\n",
       " 'renorm',\n",
       " 'renorm_',\n",
       " 'repeat',\n",
       " 'repeat_interleave',\n",
       " 'requires_grad',\n",
       " 'requires_grad_',\n",
       " 'reshape',\n",
       " 'reshape_as',\n",
       " 'resize',\n",
       " 'resize_',\n",
       " 'resize_as',\n",
       " 'resize_as_',\n",
       " 'resolve_conj',\n",
       " 'resolve_neg',\n",
       " 'retain_grad',\n",
       " 'retains_grad',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'scatter',\n",
       " 'scatter_',\n",
       " 'scatter_add',\n",
       " 'scatter_add_',\n",
       " 'select',\n",
       " 'set_',\n",
       " 'sgn',\n",
       " 'sgn_',\n",
       " 'shape',\n",
       " 'share_memory_',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'sign_',\n",
       " 'signbit',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinc',\n",
       " 'sinc_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'size',\n",
       " 'slogdet',\n",
       " 'smm',\n",
       " 'softmax',\n",
       " 'solve',\n",
       " 'sort',\n",
       " 'sparse_dim',\n",
       " 'sparse_mask',\n",
       " 'sparse_resize_',\n",
       " 'sparse_resize_and_clear_',\n",
       " 'split',\n",
       " 'split_with_sizes',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'square',\n",
       " 'square_',\n",
       " 'squeeze',\n",
       " 'squeeze_',\n",
       " 'sspaddmm',\n",
       " 'std',\n",
       " 'stft',\n",
       " 'storage',\n",
       " 'storage_offset',\n",
       " 'storage_type',\n",
       " 'stride',\n",
       " 'sub',\n",
       " 'sub_',\n",
       " 'subtract',\n",
       " 'subtract_',\n",
       " 'sum',\n",
       " 'sum_to_size',\n",
       " 'svd',\n",
       " 'swapaxes',\n",
       " 'swapaxes_',\n",
       " 'swapdims',\n",
       " 'swapdims_',\n",
       " 'symeig',\n",
       " 't',\n",
       " 't_',\n",
       " 'take',\n",
       " 'take_along_dim',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'tensor_split',\n",
       " 'tile',\n",
       " 'to',\n",
       " 'to_dense',\n",
       " 'to_mkldnn',\n",
       " 'to_sparse',\n",
       " 'to_sparse_csr',\n",
       " 'tolist',\n",
       " 'topk',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'transpose_',\n",
       " 'triangular_solve',\n",
       " 'tril',\n",
       " 'tril_',\n",
       " 'triu',\n",
       " 'triu_',\n",
       " 'true_divide',\n",
       " 'true_divide_',\n",
       " 'trunc',\n",
       " 'trunc_',\n",
       " 'type',\n",
       " 'type_as',\n",
       " 'unbind',\n",
       " 'unflatten',\n",
       " 'unfold',\n",
       " 'uniform_',\n",
       " 'unique',\n",
       " 'unique_consecutive',\n",
       " 'unsafe_chunk',\n",
       " 'unsafe_split',\n",
       " 'unsafe_split_with_sizes',\n",
       " 'unsqueeze',\n",
       " 'unsqueeze_',\n",
       " 'values',\n",
       " 'var',\n",
       " 'vdot',\n",
       " 'view',\n",
       " 'view_as',\n",
       " 'vsplit',\n",
       " 'where',\n",
       " 'xlogy',\n",
       " 'xlogy_',\n",
       " 'xpu',\n",
       " 'zero_']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5830577a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1, 2, 3]) * torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9bd33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
